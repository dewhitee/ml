{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ml_lab2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM7yysFlYLvKgW3BzlBTKpB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dewhitee/ml/blob/main/ml_lab2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1xCKlbBAWht2"
      },
      "source": [
        "import numpy as np\n",
        "import sklearn as sk\n",
        "from pandas import read_csv\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "ChCaPyXMdc3-",
        "outputId": "7cbb20e0-d3ba-4c0e-8bba-93f0ebf2cf23"
      },
      "source": [
        "# Loading dataset\n",
        "heart_failures = read_csv('heart_failure_clinical_records_dataset.csv')\n",
        "\n",
        "# Dataset shape\n",
        "total_observations, total_variables = heart_failures.shape\n",
        "print(\"Number of observations: \", total_observations)\n",
        "print(\"Number of variables: \", total_variables)\n",
        "total_x_variables = total_variables - 1\n",
        "\n",
        "heart_failures"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of observations:  299\n",
            "Number of variables:  13\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>anaemia</th>\n",
              "      <th>creatinine_phosphokinase</th>\n",
              "      <th>diabetes</th>\n",
              "      <th>ejection_fraction</th>\n",
              "      <th>high_blood_pressure</th>\n",
              "      <th>platelets</th>\n",
              "      <th>serum_creatinine</th>\n",
              "      <th>serum_sodium</th>\n",
              "      <th>sex</th>\n",
              "      <th>smoking</th>\n",
              "      <th>time</th>\n",
              "      <th>DEATH_EVENT</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>75.0</td>\n",
              "      <td>0</td>\n",
              "      <td>582</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>1</td>\n",
              "      <td>265000.00</td>\n",
              "      <td>1.9</td>\n",
              "      <td>130</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>55.0</td>\n",
              "      <td>0</td>\n",
              "      <td>7861</td>\n",
              "      <td>0</td>\n",
              "      <td>38</td>\n",
              "      <td>0</td>\n",
              "      <td>263358.03</td>\n",
              "      <td>1.1</td>\n",
              "      <td>136</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>65.0</td>\n",
              "      <td>0</td>\n",
              "      <td>146</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>162000.00</td>\n",
              "      <td>1.3</td>\n",
              "      <td>129</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>50.0</td>\n",
              "      <td>1</td>\n",
              "      <td>111</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>210000.00</td>\n",
              "      <td>1.9</td>\n",
              "      <td>137</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>65.0</td>\n",
              "      <td>1</td>\n",
              "      <td>160</td>\n",
              "      <td>1</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>327000.00</td>\n",
              "      <td>2.7</td>\n",
              "      <td>116</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>294</th>\n",
              "      <td>62.0</td>\n",
              "      <td>0</td>\n",
              "      <td>61</td>\n",
              "      <td>1</td>\n",
              "      <td>38</td>\n",
              "      <td>1</td>\n",
              "      <td>155000.00</td>\n",
              "      <td>1.1</td>\n",
              "      <td>143</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>270</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>295</th>\n",
              "      <td>55.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1820</td>\n",
              "      <td>0</td>\n",
              "      <td>38</td>\n",
              "      <td>0</td>\n",
              "      <td>270000.00</td>\n",
              "      <td>1.2</td>\n",
              "      <td>139</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>271</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>296</th>\n",
              "      <td>45.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2060</td>\n",
              "      <td>1</td>\n",
              "      <td>60</td>\n",
              "      <td>0</td>\n",
              "      <td>742000.00</td>\n",
              "      <td>0.8</td>\n",
              "      <td>138</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>278</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>297</th>\n",
              "      <td>45.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2413</td>\n",
              "      <td>0</td>\n",
              "      <td>38</td>\n",
              "      <td>0</td>\n",
              "      <td>140000.00</td>\n",
              "      <td>1.4</td>\n",
              "      <td>140</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>280</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>298</th>\n",
              "      <td>50.0</td>\n",
              "      <td>0</td>\n",
              "      <td>196</td>\n",
              "      <td>0</td>\n",
              "      <td>45</td>\n",
              "      <td>0</td>\n",
              "      <td>395000.00</td>\n",
              "      <td>1.6</td>\n",
              "      <td>136</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>285</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>299 rows × 13 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      age  anaemia  creatinine_phosphokinase  ...  smoking  time  DEATH_EVENT\n",
              "0    75.0        0                       582  ...        0     4            1\n",
              "1    55.0        0                      7861  ...        0     6            1\n",
              "2    65.0        0                       146  ...        1     7            1\n",
              "3    50.0        1                       111  ...        0     7            1\n",
              "4    65.0        1                       160  ...        0     8            1\n",
              "..    ...      ...                       ...  ...      ...   ...          ...\n",
              "294  62.0        0                        61  ...        1   270            0\n",
              "295  55.0        0                      1820  ...        0   271            0\n",
              "296  45.0        0                      2060  ...        0   278            0\n",
              "297  45.0        0                      2413  ...        1   280            0\n",
              "298  50.0        0                       196  ...        1   285            0\n",
              "\n",
              "[299 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3aYjWeyTXVuW",
        "outputId": "34bc3739-48d6-4d43-89e9-3ed2cff6b25d"
      },
      "source": [
        "# 1. Split dataset into training and testing sets\n",
        "train, test = train_test_split(heart_failures, shuffle=True,\n",
        "                               train_size=0.75, test_size=0.25)\n",
        "\n",
        "# Splitting data for training and validation\n",
        "x_train = train.values[:, :total_variables - 1]\n",
        "y_train = train.values[:, total_variables - 1]\n",
        "\n",
        "x_test = test.values[:, :total_variables - 1]\n",
        "y_test = test.values[:, total_variables - 1]\n",
        "\n",
        "print(x_train[0])\n",
        "print(len(x_train))"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[7.90e+01 1.00e+00 5.50e+01 0.00e+00 5.00e+01 1.00e+00 1.72e+05 1.80e+00\n",
            " 1.33e+02 1.00e+00 0.00e+00 7.80e+01]\n",
            "224\n",
            "y_train[0] =  0.0\n",
            "x_train[0] =  [7.90e+01 1.00e+00 5.50e+01 0.00e+00 5.00e+01 1.00e+00 1.72e+05 1.80e+00\n",
            " 1.33e+02 1.00e+00 0.00e+00 7.80e+01]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XluMTUuRmyDt",
        "outputId": "bd6a3cbd-007a-4118-9707-7bae963c32c3"
      },
      "source": [
        "print('y_train[0] = ', y_train[0])\n",
        "print('x_train[0] = ', x_train[0])\n",
        "print('x_train[1] = ', x_train[1])"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "y_train[0] =  0.0\n",
            "x_train[0] =  [7.90e+01 1.00e+00 5.50e+01 0.00e+00 5.00e+01 1.00e+00 1.72e+05 1.80e+00\n",
            " 1.33e+02 1.00e+00 0.00e+00 7.80e+01]\n",
            "x_train[1] =  [5.10e+01 0.00e+00 7.80e+01 0.00e+00 5.00e+01 0.00e+00 4.06e+05 7.00e-01\n",
            " 1.40e+02 1.00e+00 0.00e+00 7.90e+01]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6dJ5B2xCeGo1",
        "outputId": "2dac528f-7924-40ad-9081-5fb42211d4da"
      },
      "source": [
        "# 2. Single-layer perceptron algorithm\n",
        "def make_prediction(observation, weight_coefficients):\n",
        "    # Y_in = w0 + w1*x1 + w2*x2 + ... wn*xn\n",
        "    y_in = weight_coefficients[0] # W0 or activation\n",
        "    # iterating over each attribute of current observation\n",
        "    for attribute_index in range(len(observation)):\n",
        "        # + W1 * X1 + ... + Wn * Xn\n",
        "        #print('y_in += ', observation[attribute_index], \"*\", weight_coefficients[attribute_index + 1])\n",
        "        y_in += observation[attribute_index] * weight_coefficients[attribute_index + 1]\n",
        "\n",
        "    # Heaviside (calculating out_y - prediction)\n",
        "    #print('y_in = ', y_in)\n",
        "    return 0 if y_in <= 0 else 1\n",
        "\n",
        "def correct_weight_coefficients(weight_coefficients, learning_rate,\n",
        "                                observation, current_error):\n",
        "    # Correction of weight coefficients vector\n",
        "    #weight_coefficients[0] = -learning_rate * current_error\n",
        "    weight_coefficients[0] -= learning_rate * current_error\n",
        "    for i in range(1, total_x_variables):\n",
        "        #weight_coefficients[i] = -learning_rate * current_error * observation[i]\n",
        "        weight_coefficients[i] -= learning_rate * current_error * observation[i]\n",
        "\n",
        "def get_trained_weights(x_train, y_train, learning_rate = 0.1, # our alpha - value in range (0, 1)\n",
        "                    initial_value = 0.5,\n",
        "                    epochs = 10): \n",
        "    # init weight coefficients with initial_value\n",
        "    # We are adding 1 to total variables because we need to add\n",
        "    # bias weight coefficient - w0\n",
        "    weight_coefficients = [initial_value] * (total_x_variables + 1)\n",
        "    #print(f'Init weight len: {len(weight_coefficients)}, coefficients: {weight_coefficients}')\n",
        "\n",
        "    for i in range(epochs):\n",
        "        print(' --- Epoch:', i, '---')\n",
        "        y_results = []\n",
        "\n",
        "        # Sum of errors accumulated for the current epoch\n",
        "        error_sum = 0.0\n",
        "\n",
        "        # Propagation\n",
        "        for index, observation in enumerate(x_train):\n",
        "            # Get current prediction y (activation) value\n",
        "            prediction = make_prediction(observation, weight_coefficients)\n",
        "            #print('prediction = ', prediction)\n",
        "            y_results.append(prediction)\n",
        "\n",
        "            # Calculating current error value (Y - t)\n",
        "            current_error = prediction - y_train[index]\n",
        "\n",
        "            # Updating total current-epoch errors sum\n",
        "            error_sum += current_error\n",
        "\n",
        "            #print('weight_coefficients len = ', len(weight_coefficients),\n",
        "            #      ', y_results len = ', len(y_results), ', learning_rate = ', learning_rate)\n",
        "            correct_weight_coefficients(weight_coefficients, learning_rate,\n",
        "                                        observation, current_error)\n",
        "            \n",
        "            #print(\"iteration = \", index, \", error_sum =\", error_sum, \", weights: \", weight_coefficients)\n",
        "\n",
        "        print('y_results length: ', len(y_results), ', error sum: ', error_sum)\n",
        "        print('y_results: ', y_results[:10], '...', y_results[-10:])\n",
        "        print('y_train: ', y_train[:10], '...', y_train[-10:])\n",
        "        print('accuracy: ', accuracy_score(y_train, y_results))\n",
        "\n",
        "    return weight_coefficients\n",
        "\n",
        "print('y_train[0] = ', y_train[0])\n",
        "print('x_train[0] = ', x_train[0])\n",
        "\n",
        "# Train (fit) perceptron model\n",
        "model_weights = get_trained_weights(x_train, y_train, learning_rate=0.1,\n",
        "                                   initial_value=0.5,\n",
        "                                   epochs=1)\n",
        "\n",
        "predictions = []\n",
        "for observation in x_test:\n",
        "    predicted = make_prediction(observation, model_weights)\n",
        "    predictions.append(predicted)\n",
        "\n"
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "y_train[0] =  0.0\n",
            "x_train[0] =  [7.90e+01 1.00e+00 5.50e+01 0.00e+00 5.00e+01 1.00e+00 1.72e+05 1.80e+00\n",
            " 1.33e+02 1.00e+00 0.00e+00 7.80e+01]\n",
            " --- Epoch: 0 ---\n",
            "y_results length:  224 , error sum:  25.0\n",
            "y_results:  [1, 1, 0, 1, 1, 1, 0, 1, 1, 0] ... [1, 0, 0, 0, 0, 0, 0, 1, 1, 1]\n",
            "y_train:  [0. 0. 0. 1. 1. 0. 0. 0. 1. 0.] ... [0. 0. 0. 0. 0. 0. 1. 0. 0. 1.]\n",
            "accuracy:  0.5401785714285714\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wPcVPYXfrYVk",
        "outputId": "d2200c8a-7e5b-4755-83f1-082d4bcb48f4"
      },
      "source": [
        "print('y_train[:10]', y_train[:10])"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "y_train[:10] [0. 1. 0. 1. 1. 0. 0. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "82W-DGqKQin0",
        "outputId": "285f769c-c6c0-4b62-e1b3-c2847460e7ce"
      },
      "source": [
        "# Compare with keras perceptron\n",
        "from sklearn.linear_model import Perceptron\n",
        "\n",
        "slp = Perceptron(max_iter=2000, verbose=1)\n",
        "slp.fit(x_train, y_train)\n",
        "print('Predicted: ', slp.predict(x_test))"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-- Epoch 1\n",
            "Norm: 728153.47, NNZs: 12, Bias: 0.000000, T: 224, Avg. loss: 17773151676.541416\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 241143.14, NNZs: 12, Bias: 5.000000, T: 448, Avg. loss: 17942872414.078350\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 171315.13, NNZs: 12, Bias: 8.000000, T: 672, Avg. loss: 17877807942.349751\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 343419.30, NNZs: 12, Bias: 15.000000, T: 896, Avg. loss: 16276919596.776386\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 348818.15, NNZs: 12, Bias: 13.000000, T: 1120, Avg. loss: 16625258087.412907\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 181525.08, NNZs: 12, Bias: 17.000000, T: 1344, Avg. loss: 15741507095.409922\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 272234.49, NNZs: 12, Bias: 20.000000, T: 1568, Avg. loss: 14684207779.935085\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 8\n",
            "Norm: 147638.51, NNZs: 12, Bias: 22.000000, T: 1792, Avg. loss: 16907063170.022823\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 9\n",
            "Norm: 245024.07, NNZs: 12, Bias: 27.000000, T: 2016, Avg. loss: 16989543278.906397\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 10\n",
            "Norm: 145200.15, NNZs: 12, Bias: 30.000000, T: 2240, Avg. loss: 17368438342.477455\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 11\n",
            "Norm: 202054.38, NNZs: 12, Bias: 33.000000, T: 2464, Avg. loss: 14562638577.319244\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 12\n",
            "Norm: 162763.87, NNZs: 12, Bias: 41.000000, T: 2688, Avg. loss: 16291399223.379511\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 13\n",
            "Norm: 185084.17, NNZs: 12, Bias: 43.000000, T: 2912, Avg. loss: 15962853065.919464\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 14\n",
            "Norm: 180711.04, NNZs: 12, Bias: 46.000000, T: 3136, Avg. loss: 15602550787.921001\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 15\n",
            "Norm: 228056.26, NNZs: 12, Bias: 50.000000, T: 3360, Avg. loss: 17546843605.565468\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 16\n",
            "Norm: 202722.26, NNZs: 12, Bias: 57.000000, T: 3584, Avg. loss: 17370953002.487335\n",
            "Total training time: 0.01 seconds.\n",
            "Convergence after 16 epochs took 0.01 seconds\n",
            "Predicted:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0t-lE82aWQvk",
        "outputId": "97866479-b97b-4360-b430-9a505a17a357"
      },
      "source": [
        "print(x_train[:, 0])"
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[79.    51.    72.    94.    70.    63.    60.    40.    58.    63.\n",
            " 65.    55.    45.    60.    75.    69.    65.    65.    70.    42.\n",
            " 45.    60.    55.    50.    60.    80.    60.    45.    69.    75.\n",
            " 50.    50.    55.    45.    52.    43.    70.    65.    40.    49.\n",
            " 55.    62.    60.667 87.    60.    72.    50.    42.    45.    58.\n",
            " 58.    52.    81.    60.    50.    65.    65.    52.    54.    50.\n",
            " 53.    78.    58.    75.    77.    60.    55.    57.    55.    65.\n",
            " 49.    50.    95.    60.    45.    85.    65.    72.    73.    65.\n",
            " 80.    70.    75.    85.    41.    50.    60.    63.    60.    65.\n",
            " 72.    60.    50.    78.    90.    60.    63.    63.    85.    60.\n",
            " 72.    50.    72.    60.    70.    52.    75.    50.    49.    63.\n",
            " 65.    80.    40.    60.    40.    50.    65.    70.    58.    61.\n",
            " 70.    80.    70.    50.    61.    60.    53.    42.    62.    86.\n",
            " 50.    58.    61.    52.    62.    42.    45.    53.    60.    58.\n",
            " 59.    60.    53.    44.    70.    53.    40.    68.    60.    64.\n",
            " 60.    53.    46.    65.    82.    48.    70.    57.    45.    70.\n",
            " 55.    60.    58.    50.    50.    51.    65.    60.    85.    70.\n",
            " 50.    42.    46.    45.    70.    85.    50.    62.    65.    55.\n",
            " 59.    60.    70.    53.    65.    64.    55.    64.    47.    70.\n",
            " 60.    60.    45.    50.    65.    60.    55.    65.    53.    70.\n",
            " 62.    58.    90.    54.    70.    50.    73.    82.    72.    65.\n",
            " 53.    60.667 68.    67.    40.    58.    40.    50.    55.    75.\n",
            " 60.    45.    68.    55.   ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ct-9_U94v4JP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}