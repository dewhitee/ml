{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled11.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOmhxnzNRqm4iealqabDplP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dewhitee/ml/blob/main/Untitled11.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHM13lA8gXuy"
      },
      "source": [
        "import sklearn as sk"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HY6kFOVaiy_U"
      },
      "source": [
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.linear_model import Perceptron"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kTOC1L0AjBd3"
      },
      "source": [
        "# 784 - total pixel count\n",
        "x, y = fetch_openml('mnist_784', version=1, return_X_y=True)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Fi7fsYPjUZi"
      },
      "source": [
        "x_train, x_test = x[:60000], x[60000:]\n",
        "y_train, y_test = y[:60000], y[60000:]"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XktmP9Zkjr11",
        "outputId": "5518f094-784a-429c-f638-3b404a8d36ac"
      },
      "source": [
        "x_train = x_train / 255.0\n",
        "x_test = x_test / 255.0\n",
        "\n",
        "slp = Perceptron(max_iter=20, verbose=1)\n",
        "slp.fit(x_train, y_train)\n",
        "\n",
        "print('Train acc: ', slp.score(x_train, y_train))\n",
        "print('Test acc: ', slp.score(x_test, y_test))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "-- Epoch 1\n",
            "Norm: 54.18, NNZs: 664, Bias: -1.000000, T: 60000, Avg. loss: 0.039358\n",
            "Total training time: 0.11 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 68.00, NNZs: 669, Bias: -1.000000, T: 120000, Avg. loss: 0.016518\n",
            "Total training time: 0.22 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 76.41, NNZs: 676, Bias: -1.000000, T: 180000, Avg. loss: 0.013100\n",
            "Total training time: 0.32 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 83.06, NNZs: 676, Bias: -1.000000, T: 240000, Avg. loss: 0.011740\n",
            "Total training time: 0.42 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 88.66, NNZs: 678, Bias: -1.000000, T: 300000, Avg. loss: 0.010954\n",
            "Total training time: 0.55 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 93.32, NNZs: 679, Bias: -1.000000, T: 360000, Avg. loss: 0.010041\n",
            "Total training time: 0.67 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 97.71, NNZs: 682, Bias: -1.000000, T: 420000, Avg. loss: 0.009475\n",
            "Total training time: 0.78 seconds.\n",
            "-- Epoch 8\n",
            "Norm: 101.75, NNZs: 683, Bias: -1.000000, T: 480000, Avg. loss: 0.009089\n",
            "Total training time: 0.90 seconds.\n",
            "-- Epoch 9\n",
            "Norm: 105.52, NNZs: 683, Bias: -1.000000, T: 540000, Avg. loss: 0.008969\n",
            "Total training time: 1.01 seconds.\n",
            "Convergence after 9 epochs took 1.01 seconds\n",
            "-- Epoch 1\n",
            "Norm: 4.98, NNZs: 599, Bias: 0.000000, T: 60000, Avg. loss: 0.014708\n",
            "Total training time: 0.12 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 9.68, NNZs: 618, Bias: 0.000000, T: 120000, Avg. loss: 0.013740\n",
            "Total training time: 0.23 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 14.09, NNZs: 629, Bias: 0.000000, T: 180000, Avg. loss: 0.013307\n",
            "Total training time: 0.35 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 18.37, NNZs: 640, Bias: 0.000000, T: 240000, Avg. loss: 0.013239\n",
            "Total training time: 0.48 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 22.84, NNZs: 647, Bias: 0.000000, T: 300000, Avg. loss: 0.012779\n",
            "Total training time: 0.60 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 27.17, NNZs: 651, Bias: 0.000000, T: 360000, Avg. loss: 0.012073\n",
            "Total training time: 0.70 seconds.\n",
            "Convergence after 6 epochs took 0.70 seconds\n",
            "-- Epoch 1\n",
            "Norm: 52.12, NNZs: 670, Bias: -1.000000, T: 60000, Avg. loss: 0.058912\n",
            "Total training time: 0.12 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 72.60, NNZs: 678, Bias: 0.000000, T: 120000, Avg. loss: 0.030908\n",
            "Total training time: 0.22 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 84.44, NNZs: 684, Bias: -1.000000, T: 180000, Avg. loss: 0.026067\n",
            "Total training time: 0.34 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 93.27, NNZs: 688, Bias: -1.000000, T: 240000, Avg. loss: 0.024909\n",
            "Total training time: 0.44 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 100.69, NNZs: 689, Bias: -1.000000, T: 300000, Avg. loss: 0.023186\n",
            "Total training time: 0.55 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 107.26, NNZs: 690, Bias: -1.000000, T: 360000, Avg. loss: 0.022829\n",
            "Total training time: 0.66 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 113.00, NNZs: 691, Bias: -1.000000, T: 420000, Avg. loss: 0.023096\n",
            "Total training time: 0.76 seconds.\n",
            "-- Epoch 8\n",
            "Norm: 118.05, NNZs: 693, Bias: -1.000000, T: 480000, Avg. loss: 0.022405\n",
            "Total training time: 0.88 seconds.\n",
            "-- Epoch 9\n",
            "Norm: 122.90, NNZs: 694, Bias: -1.000000, T: 540000, Avg. loss: 0.021661\n",
            "Total training time: 0.98 seconds.\n",
            "-- Epoch 10\n",
            "Norm: 127.31, NNZs: 695, Bias: 0.000000, T: 600000, Avg. loss: 0.021760\n",
            "Total training time: 1.09 seconds.\n",
            "Convergence after 10 epochs took 1.09 seconds\n",
            "-- Epoch 1\n",
            "Norm: 52.52, NNZs: 653, Bias: -1.000000, T: 60000, Avg. loss: 0.059624\n",
            "Total training time: 0.11 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 71.08, NNZs: 662, Bias: -1.000000, T: 120000, Avg. loss: 0.032457\n",
            "Total training time: 0.22 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 81.88, NNZs: 663, Bias: -1.000000, T: 180000, Avg. loss: 0.028707\n",
            "Total training time: 0.33 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 90.13, NNZs: 667, Bias: -1.000000, T: 240000, Avg. loss: 0.026612\n",
            "Total training time: 0.43 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 96.65, NNZs: 669, Bias: -1.000000, T: 300000, Avg. loss: 0.025785\n",
            "Total training time: 0.53 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 102.16, NNZs: 671, Bias: -1.000000, T: 360000, Avg. loss: 0.025150\n",
            "Total training time: 0.64 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 107.61, NNZs: 674, Bias: -1.000000, T: 420000, Avg. loss: 0.024004\n",
            "Total training time: 0.75 seconds.\n",
            "-- Epoch 8\n",
            "Norm: 112.03, NNZs: 675, Bias: -1.000000, T: 480000, Avg. loss: 0.024091\n",
            "Total training time: 0.86 seconds.\n",
            "-- Epoch 9\n",
            "Norm: 116.34, NNZs: 676, Bias: -1.000000, T: 540000, Avg. loss: 0.023635\n",
            "Total training time: 0.97 seconds.\n",
            "-- Epoch 10\n",
            "Norm: 120.23, NNZs: 677, Bias: -1.000000, T: 600000, Avg. loss: 0.023514\n",
            "Total training time: 1.08 seconds.\n",
            "-- Epoch 11\n",
            "Norm: 123.84, NNZs: 677, Bias: -1.000000, T: 660000, Avg. loss: 0.023101\n",
            "Total training time: 1.19 seconds.\n",
            "-- Epoch 12\n",
            "Norm: 127.05, NNZs: 677, Bias: -1.000000, T: 720000, Avg. loss: 0.023318\n",
            "Total training time: 1.29 seconds.\n",
            "Convergence after 12 epochs took 1.29 seconds\n",
            "-- Epoch 1\n",
            "Norm: 17.40, NNZs: 655, Bias: 0.000000, T: 60000, Avg. loss: 0.051661\n",
            "Total training time: 0.11 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 34.56, NNZs: 672, Bias: -1.000000, T: 120000, Avg. loss: 0.047058\n",
            "Total training time: 0.22 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 50.57, NNZs: 673, Bias: -1.000000, T: 180000, Avg. loss: 0.041311\n",
            "Total training time: 0.33 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 67.20, NNZs: 678, Bias: -1.000000, T: 240000, Avg. loss: 0.037200\n",
            "Total training time: 0.44 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 83.02, NNZs: 679, Bias: 0.000000, T: 300000, Avg. loss: 0.032668\n",
            "Total training time: 0.56 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 96.13, NNZs: 681, Bias: -1.000000, T: 360000, Avg. loss: 0.029614\n",
            "Total training time: 0.69 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 106.78, NNZs: 683, Bias: -1.000000, T: 420000, Avg. loss: 0.026872\n",
            "Total training time: 0.80 seconds.\n",
            "-- Epoch 8\n",
            "Norm: 115.35, NNZs: 683, Bias: -1.000000, T: 480000, Avg. loss: 0.024785\n",
            "Total training time: 0.93 seconds.\n",
            "-- Epoch 9\n",
            "Norm: 122.71, NNZs: 685, Bias: -1.000000, T: 540000, Avg. loss: 0.023445\n",
            "Total training time: 1.05 seconds.\n",
            "-- Epoch 10\n",
            "Norm: 129.59, NNZs: 685, Bias: 0.000000, T: 600000, Avg. loss: 0.022916\n",
            "Total training time: 1.17 seconds.\n",
            "-- Epoch 11\n",
            "Norm: 135.91, NNZs: 685, Bias: -1.000000, T: 660000, Avg. loss: 0.021718\n",
            "Total training time: 1.29 seconds.\n",
            "-- Epoch 12\n",
            "Norm: 141.68, NNZs: 686, Bias: 0.000000, T: 720000, Avg. loss: 0.021503\n",
            "Total training time: 1.40 seconds.\n",
            "-- Epoch 13\n",
            "Norm: 146.79, NNZs: 686, Bias: 0.000000, T: 780000, Avg. loss: 0.020820\n",
            "Total training time: 1.53 seconds.\n",
            "-- Epoch 14\n",
            "Norm: 151.54, NNZs: 686, Bias: -1.000000, T: 840000, Avg. loss: 0.020516\n",
            "Total training time: 1.64 seconds.\n",
            "-- Epoch 15\n",
            "Norm: 155.83, NNZs: 686, Bias: 0.000000, T: 900000, Avg. loss: 0.020364\n",
            "Total training time: 1.74 seconds.\n",
            "-- Epoch 16\n",
            "Norm: 159.85, NNZs: 686, Bias: 0.000000, T: 960000, Avg. loss: 0.019829\n",
            "Total training time: 1.85 seconds.\n",
            "Convergence after 16 epochs took 1.85 seconds\n",
            "-- Epoch 1\n",
            "Norm: 7.97, NNZs: 636, Bias: -1.000000, T: 60000, Avg. loss: 0.036187\n",
            "Total training time: 0.10 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 14.61, NNZs: 657, Bias: 0.000000, T: 120000, Avg. loss: 0.034048\n",
            "Total training time: 0.21 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 20.37, NNZs: 666, Bias: -1.000000, T: 180000, Avg. loss: 0.031646\n",
            "Total training time: 0.31 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 25.70, NNZs: 668, Bias: -1.000000, T: 240000, Avg. loss: 0.030949\n",
            "Total training time: 0.42 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 30.98, NNZs: 674, Bias: -1.000000, T: 300000, Avg. loss: 0.030200\n",
            "Total training time: 0.52 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 36.44, NNZs: 678, Bias: 0.000000, T: 360000, Avg. loss: 0.029425\n",
            "Total training time: 0.65 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 41.67, NNZs: 679, Bias: 0.000000, T: 420000, Avg. loss: 0.029404\n",
            "Total training time: 0.75 seconds.\n",
            "-- Epoch 8\n",
            "Norm: 47.39, NNZs: 681, Bias: 0.000000, T: 480000, Avg. loss: 0.028433\n",
            "Total training time: 0.86 seconds.\n",
            "Convergence after 8 epochs took 0.86 seconds\n",
            "-- Epoch 1\n",
            "Norm: 51.23, NNZs: 653, Bias: -1.000000, T: 60000, Avg. loss: 0.055904\n",
            "Total training time: 0.11 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 76.89, NNZs: 661, Bias: -1.000000, T: 120000, Avg. loss: 0.026346\n",
            "Total training time: 0.22 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 90.71, NNZs: 665, Bias: -1.000000, T: 180000, Avg. loss: 0.020237\n",
            "Total training time: 0.32 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 100.52, NNZs: 665, Bias: -1.000000, T: 240000, Avg. loss: 0.018091\n",
            "Total training time: 0.43 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 108.37, NNZs: 667, Bias: -1.000000, T: 300000, Avg. loss: 0.017367\n",
            "Total training time: 0.53 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 114.78, NNZs: 667, Bias: -1.000000, T: 360000, Avg. loss: 0.016509\n",
            "Total training time: 0.64 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 120.25, NNZs: 670, Bias: -1.000000, T: 420000, Avg. loss: 0.015894\n",
            "Total training time: 0.74 seconds.\n",
            "-- Epoch 8\n",
            "Norm: 125.08, NNZs: 672, Bias: 0.000000, T: 480000, Avg. loss: 0.015357\n",
            "Total training time: 0.85 seconds.\n",
            "-- Epoch 9\n",
            "Norm: 129.51, NNZs: 673, Bias: -1.000000, T: 540000, Avg. loss: 0.015162\n",
            "Total training time: 0.97 seconds.\n",
            "Convergence after 9 epochs took 0.97 seconds\n",
            "-- Epoch 1\n",
            "Norm: 8.76, NNZs: 627, Bias: 0.000000, T: 60000, Avg. loss: 0.025593\n",
            "Total training time: 0.12 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 14.59, NNZs: 645, Bias: 0.000000, T: 120000, Avg. loss: 0.019456\n",
            "Total training time: 0.23 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 20.18, NNZs: 650, Bias: 0.000000, T: 180000, Avg. loss: 0.018022\n",
            "Total training time: 0.35 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 25.79, NNZs: 654, Bias: 0.000000, T: 240000, Avg. loss: 0.017859\n",
            "Total training time: 0.46 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 31.65, NNZs: 659, Bias: 0.000000, T: 300000, Avg. loss: 0.017321\n",
            "Total training time: 0.58 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 37.24, NNZs: 662, Bias: 0.000000, T: 360000, Avg. loss: 0.016545\n",
            "Total training time: 0.70 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 43.31, NNZs: 665, Bias: 0.000000, T: 420000, Avg. loss: 0.016939\n",
            "Total training time: 0.82 seconds.\n",
            "-- Epoch 8\n",
            "Norm: 49.16, NNZs: 669, Bias: 0.000000, T: 480000, Avg. loss: 0.015510\n",
            "Total training time: 0.94 seconds.\n",
            "-- Epoch 9\n",
            "Norm: 54.82, NNZs: 674, Bias: 0.000000, T: 540000, Avg. loss: 0.015289\n",
            "Total training time: 1.06 seconds.\n",
            "-- Epoch 10\n",
            "Norm: 60.74, NNZs: 676, Bias: 0.000000, T: 600000, Avg. loss: 0.014145\n",
            "Total training time: 1.18 seconds.\n",
            "-- Epoch 11\n",
            "Norm: 66.30, NNZs: 680, Bias: 1.000000, T: 660000, Avg. loss: 0.014012\n",
            "Total training time: 1.30 seconds.\n",
            "-- Epoch 12\n",
            "Norm: 71.54, NNZs: 680, Bias: 0.000000, T: 720000, Avg. loss: 0.013916\n",
            "Total training time: 1.42 seconds.\n",
            "-- Epoch 13\n",
            "Norm: 76.82, NNZs: 682, Bias: 0.000000, T: 780000, Avg. loss: 0.013988\n",
            "Total training time: 1.54 seconds.\n",
            "-- Epoch 14\n",
            "Norm: 82.09, NNZs: 682, Bias: 0.000000, T: 840000, Avg. loss: 0.013786\n",
            "Total training time: 1.65 seconds.\n",
            "-- Epoch 15\n",
            "Norm: 87.12, NNZs: 684, Bias: -1.000000, T: 900000, Avg. loss: 0.014394\n",
            "Total training time: 1.78 seconds.\n",
            "Convergence after 15 epochs took 1.78 seconds\n",
            "-- Epoch 1\n",
            "Norm: 47.25, NNZs: 666, Bias: -1.000000, T: 60000, Avg. loss: 0.061864\n",
            "Total training time: 0.12 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 60.79, NNZs: 674, Bias: -1.000000, T: 120000, Avg. loss: 0.039394\n",
            "Total training time: 0.25 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 68.72, NNZs: 681, Bias: -1.000000, T: 180000, Avg. loss: 0.036525\n",
            "Total training time: 0.37 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 75.31, NNZs: 683, Bias: -1.000000, T: 240000, Avg. loss: 0.034990\n",
            "Total training time: 0.48 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 81.19, NNZs: 685, Bias: -1.000000, T: 300000, Avg. loss: 0.033807\n",
            "Total training time: 0.60 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 86.69, NNZs: 686, Bias: -1.000000, T: 360000, Avg. loss: 0.033718\n",
            "Total training time: 0.72 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 92.16, NNZs: 686, Bias: -2.000000, T: 420000, Avg. loss: 0.033845\n",
            "Total training time: 0.84 seconds.\n",
            "-- Epoch 8\n",
            "Norm: 97.25, NNZs: 687, Bias: -1.000000, T: 480000, Avg. loss: 0.033679\n",
            "Total training time: 0.96 seconds.\n",
            "-- Epoch 9\n",
            "Norm: 102.11, NNZs: 687, Bias: -2.000000, T: 540000, Avg. loss: 0.034274\n",
            "Total training time: 1.08 seconds.\n",
            "-- Epoch 10\n",
            "Norm: 107.26, NNZs: 689, Bias: -1.000000, T: 600000, Avg. loss: 0.034806\n",
            "Total training time: 1.20 seconds.\n",
            "Convergence after 10 epochs took 1.20 seconds\n",
            "-- Epoch 1\n",
            "Norm: 31.49, NNZs: 665, Bias: -1.000000, T: 60000, Avg. loss: 0.072354\n",
            "Total training time: 0.12 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 61.69, NNZs: 673, Bias: 0.000000, T: 120000, Avg. loss: 0.055392\n",
            "Total training time: 0.23 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 79.64, NNZs: 682, Bias: -1.000000, T: 180000, Avg. loss: 0.044374\n",
            "Total training time: 0.34 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 91.06, NNZs: 685, Bias: -1.000000, T: 240000, Avg. loss: 0.040151\n",
            "Total training time: 0.45 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 100.05, NNZs: 686, Bias: -1.000000, T: 300000, Avg. loss: 0.037342\n",
            "Total training time: 0.56 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 107.88, NNZs: 687, Bias: -1.000000, T: 360000, Avg. loss: 0.035825\n",
            "Total training time: 0.67 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 114.83, NNZs: 688, Bias: -1.000000, T: 420000, Avg. loss: 0.035243\n",
            "Total training time: 0.77 seconds.\n",
            "-- Epoch 8\n",
            "Norm: 121.20, NNZs: 690, Bias: -2.000000, T: 480000, Avg. loss: 0.034309\n",
            "Total training time: 0.88 seconds.\n",
            "-- Epoch 9\n",
            "Norm: 126.92, NNZs: 693, Bias: -1.000000, T: 540000, Avg. loss: 0.033078\n",
            "Total training time: 1.00 seconds.\n",
            "-- Epoch 10\n",
            "Norm: 132.21, NNZs: 694, Bias: -1.000000, T: 600000, Avg. loss: 0.032876\n",
            "Total training time: 1.12 seconds.\n",
            "-- Epoch 11\n",
            "Norm: 137.23, NNZs: 696, Bias: -1.000000, T: 660000, Avg. loss: 0.031759\n",
            "Total training time: 1.24 seconds.\n",
            "-- Epoch 12\n",
            "Norm: 141.90, NNZs: 696, Bias: -1.000000, T: 720000, Avg. loss: 0.031613\n",
            "Total training time: 1.35 seconds.\n",
            "-- Epoch 13\n",
            "Norm: 146.47, NNZs: 696, Bias: 0.000000, T: 780000, Avg. loss: 0.031288\n",
            "Total training time: 1.48 seconds.\n",
            "-- Epoch 14\n",
            "Norm: 150.46, NNZs: 696, Bias: -1.000000, T: 840000, Avg. loss: 0.031128\n",
            "Total training time: 1.60 seconds.\n",
            "-- Epoch 15\n",
            "Norm: 154.27, NNZs: 696, Bias: -1.000000, T: 900000, Avg. loss: 0.029816\n",
            "Total training time: 1.72 seconds.\n",
            "-- Epoch 16\n",
            "Norm: 157.69, NNZs: 698, Bias: -1.000000, T: 960000, Avg. loss: 0.030123\n",
            "Total training time: 1.84 seconds.\n",
            "-- Epoch 17\n",
            "Norm: 161.06, NNZs: 698, Bias: -1.000000, T: 1020000, Avg. loss: 0.030227\n",
            "Total training time: 1.96 seconds.\n",
            "-- Epoch 18\n",
            "Norm: 164.21, NNZs: 698, Bias: 0.000000, T: 1080000, Avg. loss: 0.029388\n",
            "Total training time: 2.08 seconds.\n",
            "-- Epoch 19\n",
            "Norm: 167.33, NNZs: 698, Bias: -1.000000, T: 1140000, Avg. loss: 0.029321\n",
            "Total training time: 2.19 seconds.\n",
            "-- Epoch 20\n",
            "Norm: 170.05, NNZs: 698, Bias: -1.000000, T: 1200000, Avg. loss: 0.029311\n",
            "Total training time: 2.31 seconds.\n",
            "Convergence after 20 epochs took 2.31 seconds\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   13.1s finished\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train acc:  0.69935\n",
            "Test acc:  0.6512\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lsFkg6CWk5I8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}